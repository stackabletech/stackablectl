---
apiVersion: spark.stackable.tech/v1alpha1
kind: SparkApplication
metadata:
  name: spark-e-s3
spec:
  version: "1.0"
  sparkImage: docker.stackable.tech/stackable/spark-k8s:3.3.0-stackable0.99.0 #local ARM version
  sparkImagePullPolicy: IfNotPresent
  mode: cluster
  mainClass: tbd
  mainApplicationFile: s3a://my-bucket/.jar
  s3bucket:
    inline:
      bucketName: my-bucket
      connection:
        inline:
          host: test-minio
          port: 9000
          accessStyle: Path
          credentials:
            secretClass: s3-credentials-class
  volumes:
    - name: spark-pi-deps
      persistentVolumeClaim:
        claimName: spark-private-pvc
    - name: config-volume-hbase
      configMap:
        name: hbase-master-default
  sparkConf:
    spark.hadoop.fs.s3a.aws.credentials.provider: "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider"
    spark.driver.extraClassPath: "/dependencies/hbase-site.xml"
    spark.executor.extraClassPath: "/dependencies/hbase-site.xml"
  driver:
    cores: 1
    coreLimit: "1200m"
    memory: "512m"
    volumeMounts:
      - name: spark-pi-deps
        mountPath: /dependencies/jars
      - name: config-volume-hbase
        mountPath: /stackable/conf/hbase-site.xml
        subPath: hbase-site.xml
    nodeSelector:
      node: "1"
  executor:
    cores: 1
    instances: 1
    memory: "512m"
    volumeMounts:
      - name: spark-pi-deps
        mountPath: /dependencies/jars
      - name: config-volume-hbase
        mountPath: /stackable/conf/hbase-site.xml
        subPath: hbase-site.xml
    nodeSelector:
      node: "1"


