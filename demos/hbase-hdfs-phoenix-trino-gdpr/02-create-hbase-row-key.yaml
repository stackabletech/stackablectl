---
apiVersion: batch/v1
kind: Job
metadata:
  name: create-hbase-row-key
spec:
  template:
    spec:
      containers:
        - name: create-hbase-row-key
          image: "bitnami/python:latest"
          env:
            - name: INPUT_FILE_NAME
              value: "events.tgz"
            - name: OUTPUT_FILE_NAME
              value: "hashed_events.tgz"
            - name: CSV_FILE_NAME
              value: "events.csv"
          command: ["bash", "-c", "pip install pandas minio && \  
                                   python -u /tmp/script/script.py -i $INPUT_FILE_NAME -o $OUTPUT_FILE_NAME -c $CSV_FILE_NAME && \                                    
                                    sleep infinity"]
          volumeMounts:
            - name: script
              mountPath: /tmp/script
      volumes:
        - name: script
          configMap:
            name: generate-hash-row-key
      restartPolicy: OnFailure
  backoffLimit: 50
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: generate-hash-row-key
data:
  script.py: |
    import argparse
    import hashlib
    import pandas as pd
    from minio import Minio
    import tarfile
  
    def parse_args():
      parser = argparse.ArgumentParser(
      description=""
      )
      
      parser.add_argument(
      "-i",
      "--input_file",
      type=str,
      help="Name of the CSV input file.",
      required=True
      )
      
      parser.add_argument(
      "-o",
      "--output_file_name",
      type=str,
      help="Name of the compressed CSV output file.",
      required=True
      )
      
      parser.add_argument(
      "-c",
      "--csv_file_name",
      type=str,
      help="Name of the CSV file.",
      required=True
      )
      
      return parser.parse_args()
    
    
    def main():
      
      args = parse_args()
      
      LOCAL_FILE_PATH = '/tmp/'
      ACCESS_KEY = 'demo'
      SECRET_KEY = 'demodemo'
      BUCKET_NAME = 'demo-bucket'
      CSV_FILE_NAME = args.csv_file_name
      OBJECT_NAME = args.input_file
      OUTPUT_FILE_NAME = args.output_file_name
      MINIO_HOST = 'demo-minio-hbase'
      MINIO_PORT = '9000'
      MINIO_CLIENT = Minio(MINIO_HOST + ':' + MINIO_PORT, access_key=ACCESS_KEY, secret_key=SECRET_KEY, secure=False)
      
      MINIO_CLIENT.fget_object(BUCKET_NAME, OBJECT_NAME, LOCAL_FILE_PATH + OBJECT_NAME )
      
      file = tarfile.open(LOCAL_FILE_PATH + OBJECT_NAME)
      file.extractall(LOCAL_FILE_PATH)
      df = pd.read_csv(LOCAL_FILE_PATH + CSV_FILE_NAME)
      
      df2 = df.assign(concat_col=lambda x: (x.visitorid).astype(str) + (x.timestamp).astype(str) )
      
      df2['hash_col'] = df2['concat_col'].apply(lambda x:hashlib.sha256(x.encode()).hexdigest())
      
      df3 = df2[ ['hash_col'] + [ col for col in df2.columns if col != 'hash_col' ]]
      
      df3.to_csv(LOCAL_FILE_PATH + OUTPUT_FILE_NAME,columns=['hash_col','timestamp','visitorid','event','itemid','transactionid'], compression='gzip', sep=';', encoding='utf-8', index=False, na_rep='N/A')
      
      result = MINIO_CLIENT.fput_object(BUCKET_NAME, OUTPUT_FILE_NAME, LOCAL_FILE_PATH + OUTPUT_FILE_NAME)
      
      print("created {0} object; etag: {1}, version-id: {2}".format(
            result.object_name, result.etag, result.version_id,),)
    
    if __name__ == "__main__":
      main()