---
apiVersion: batch/v1
kind: Job
metadata:
  name: ingest-test-data
spec:
  template:
    spec:
      containers:
        - name: ingest-test-data
          image: docker.stackable.tech/stackable/testing-tools:0.1.0-stackable0.1.0
          command: ["bash", "-c", "python -u /tmp/script/script.py"]
          volumeMounts:
            - name: script
              mountPath: /tmp/script
      restartPolicy: OnFailure
      volumes:
      - name: script
        configMap:
          name: ingest-test-data-script
      restartPolicy: Never
  backoffLimit: 50 # It can take some time until Kafka is ready
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ingest-test-data-script
data:
  script.py: |
    import json
    from kafka3 import KafkaProducer
    import pandas as pd
    import time

    HISTORY_DAYS = 1
    # At a maximum scrape once every minute.
    # In practice it will take longer than a minute to scrape, so the loop will be busy.
    # This will result in a continuos stream of data.
    LIVE_UPDATE_INTERVAL_S = 60

    BOOTSTRAP_SERVERS = "kafka:9092"
    # BOOTSTRAP_SERVERS = "172.18.0.2:32316"
    STATIONS_TOPIC = "stations"
    MEASUREMENTS_TOPIC = "measurements"

    print(f"Producing station records to topic {STATIONS_TOPIC} with bootstrap servers {BOOTSTRAP_SERVERS}\n")
    producer = KafkaProducer(bootstrap_servers=BOOTSTRAP_SERVERS)

    stations = pd.read_json("https://www.pegelonline.wsv.de/webservices/rest-api/v2/stations.json")
    print(f"Stations:\n{stations}")
    for station in stations.index:
        station_json = stations.loc[station].to_json()
        producer.send(STATIONS_TOPIC, str.encode(station_json))

    print(f"Producing measurement records of the last {HISTORY_DAYS} days to topic {MEASUREMENTS_TOPIC} with bootstrap servers {BOOTSTRAP_SERVERS}\n")

    # Using separate loop to first send stations and the measurements afterwards
    for station in stations.index:
        station = stations.loc[station]
        station_uuid = station["uuid"]
        url = f"https://www.pegelonline.wsv.de/webservices/rest-api/v2/stations/{station_uuid}/W/measurements.json?start=P{HISTORY_DAYS}D"
        try:
            measurements = pd.read_json(url)
        except Exception as err:
            print(f"[WARN] Could not read measurements for station {station['longname']} ({station_uuid}): {err}")
            continue
        measurements['station_uuid'] = station_uuid
        for measurement in measurements.index:
            measurement_json = measurements.loc[measurement].to_json()
            producer.send(MEASUREMENTS_TOPIC, str.encode(measurement_json))

        print(f"Send {len(measurements)} measurements for station {station['longname']}")


    print(f"Finished loading {HISTORY_DAYS} days of historic data, now starting live streaming")
    while True:
        starttime = time.time()
        measurement_counter = 0
        measurement_failed_counter = 0
        for station_uuid in stations["uuid"]:
            url = f"https://www.pegelonline.wsv.de/webservices/rest-api/v2/stations/{station_uuid}/W/currentmeasurement.json"
            try:
                measurement = pd.read_json(url, typ='series')
            except Exception as err:
                measurement_failed_counter += 1
                continue

            measurement = {
                "timestamp": int(time.time() * 1000),
                "value": measurement["value"],
                "station_uuid": station_uuid
            }
            measurement_json = json.dumps(measurement, separators=(',', ':'))
            producer.send(MEASUREMENTS_TOPIC, str.encode(measurement_json))
            measurement_counter += 1
        print(f"Send {measurement_counter} measurements in {int(time.time() - starttime)}s ({measurement_failed_counter} failed)")
        time.sleep(max(0, LIVE_UPDATE_INTERVAL_S - ((time.time() - starttime))))
