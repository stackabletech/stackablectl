---
apiVersion: batch/v1
kind: Job
metadata:
  name: start-date-job
spec:
  template:
    spec:
      containers:
        - name: start-date-job
          image: docker.stackable.tech/stackable/tools:1.0.0-stackable23.4
          # N.B. it is possible for the scheduler to report that a DAG exists, only for the worker task to fail if a pod is unexpectedly
          # restarted. Additionally, the db-init job takes a few minutes to complete before the cluster is deployed. The wait/watch steps
          # below are not "water-tight" but add a layer of stability by at least ensuring that the db is initialized and ready and that
          # all pods are reachable (albeit independent of each other).
          command: ["bash", "-c", "
            kubectl wait airflowdb/airflow --for jsonpath='{.status.condition}'=Ready --timeout 600s
            && kubectl rollout status --watch statefulset/airflow-webserver-default
            && kubectl rollout status --watch statefulset/airflow-worker-default
            && kubectl rollout status --watch statefulset/airflow-scheduler-default
            && export AIRFLOW_ADMIN_PASSWORD=$(cat /airflow-credentials/adminUser.password)
            && curl -i -s --user admin:$AIRFLOW_ADMIN_PASSWORD http://airflow-webserver-default:8080/api/v1/dags/date_demo
            && curl -i -s --user admin:$AIRFLOW_ADMIN_PASSWORD -H 'Content-Type:application/json' -XPATCH http://airflow-webserver-default:8080/api/v1/dags/date_demo -d '{\"is_paused\": false}'
            && curl -i -s --user admin:$AIRFLOW_ADMIN_PASSWORD -H 'Content-Type:application/json' -XPOST http://airflow-webserver-default:8080/api/v1/dags/date_demo/dagRuns -d '{}'
          "]
          volumeMounts:
            - name: airflow-credentials
              mountPath: /airflow-credentials
      volumes:
        - name: airflow-credentials
          secret:
            secretName: airflow-credentials
      restartPolicy: OnFailure
  backoffLimit: 20 # give some time for the Airflow cluster to be available
