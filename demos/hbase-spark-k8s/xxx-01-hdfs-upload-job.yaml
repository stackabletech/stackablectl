---
apiVersion: batch/v1
kind: Job
metadata:
  name: spark-hbase-connections-hdfs-upload-job-5
spec:
  template:
    spec:
      nodeSelector:
        node: "1"
      restartPolicy: Never
      volumes:
        - name: config-volume-hdfs
          configMap:
            name: hdfs
      containers:
        - name: load-ny-taxi-data
          image: docker.stackable.tech/stackable/hadoop:3.3.3-stackable0.99.0
          command: ["bash", "-c", "bin/hdfs dfs -mkdir /data "]
          volumeMounts:
            - name: config-volume-hdfs
              mountPath: /stackable/conf/hdfs
          securityContext:
            runAsUser: 0

  #\
  #&& cd /tmp && for month in 2020-01 2020-02 2020-03 2020-04 2020-05 2020-06 2020-07 2020-08 2020-09 2020-10 2020-11 2020-12 2021-01 2021-02 2021-03 2021-04 2021-05 2021-06 2021-07 2021-08 2021-09 2021-10 2021-11 2021-12 2022-01 2022-02 2022-03 2022-04; \
  #do curl -O https://repo.stackable.tech/repository/misc/ny-taxi-data/yellow_tripdata_$month.parquet \
  #&& bin/hdfs dfs -put /tmp/yellow_tripdata_$month.parquet /data; done


#--> Creates Error:
#  WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable