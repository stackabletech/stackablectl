{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea56f75f-bb0d-425c-9276-ab4accb01e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install psycopg2-binary\n",
    "#!pip install -U tsfresh\n",
    "#!pip install alibi-detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ddf42a5-e91e-46c2-9634-6a97392c38bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['OutlierAEGMM',\n",
       " 'IForest',\n",
       " 'Mahalanobis',\n",
       " 'OutlierAE',\n",
       " 'OutlierVAE',\n",
       " 'OutlierVAEGMM',\n",
       " 'OutlierSeq2Seq',\n",
       " 'SpectralResidual',\n",
       " 'LLR',\n",
       " 'OutlierProphet']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import alibi_detect\n",
    "from alibi_detect.od import SpectralResidual\n",
    "\n",
    "alibi_detect.od.__all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71cfd924-ee93-4f19-a8e6-b4d0184b54d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(\"postgresql://admin:adminadmin@postgresql-timescaledb.default.svc.cluster.local:5432/tsdb\")\n",
    "last_time = \"1970-01-01\"\n",
    "cols = ['r1', 'r2', 'r3', 'r4', 'r5', 'r6', 'r7', 'r8', 'r9', 'r10', 'r11', 'r12', 'r13', 'r14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05acfe33-a647-413f-82c8-ab2e8ee835b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iteration: 2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next offset: 2023-06-23 11:53:20.519999 , fetched: 39\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    display('Iteration: '+str(i))\n",
    "    \n",
    "    sql = f\"\"\"\\\n",
    "            SELECT time, {', '.join(cols)}\n",
    "            from conditions \n",
    "            where (timestamp '{last_time}' = timestamp '1970-01-01' or time > timestamp '{last_time}') and time < now()\n",
    "            order by time asc \n",
    "            limit 1000\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_sql_query(sql, engine)\n",
    "    df_scores = df[['time']].copy()\n",
    "    \n",
    "    od = SpectralResidual(\n",
    "        threshold=1.,\n",
    "        window_amp=20,\n",
    "        window_local=20,\n",
    "        padding_amp_method='reflect',\n",
    "        padding_local_method='reflect',\n",
    "        padding_amp_side='bilateral',\n",
    "        n_est_points=10,\n",
    "        n_grad_points=5\n",
    "    )\n",
    "    \n",
    "    for col in cols:\n",
    "        result = od.predict(\n",
    "            df[col].to_numpy(),\n",
    "            t=None,\n",
    "            return_instance_score=True\n",
    "        )\n",
    "        df_scores[col+'_score'] = result['data']['instance_score'].tolist()\n",
    "    \n",
    "    df_scores.to_sql('scores_sr', engine, index=False, if_exists='append')\n",
    "    \n",
    "    # get last timestamp to use for next offset\n",
    "    last_time = pd.to_datetime(df.time.tail(1).values[0]).strftime('%Y-%m-%d %H:%M:%S.%f %Z')\n",
    "    print(f'Next offset: {last_time}, fetched: {df_scores.r1_score.size}')\n",
    "    \n",
    "    time.sleep(12)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44c3e8-d288-40f2-8144-fbe6b1da3f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "# -----\n",
    "# *DONE* - the SELECT should get all rows since the last call: i.e. the last ts has to cached and used as a baseline for the next call. Initially set to zero, NaN etc.\n",
    "# *DONE* - this means we have no overlap and the outlier scores will not be persisted multiple times. alternatively we could average over the whole window.\n",
    "# *DONE* - combine result_r1['data']#['instance_score'] with the original data frame's timestamp and write out to a new table. We can combine models in the same table.\n",
    "# *DONE* - move scores_sr table into the demo yaml to avoid the permissions issue\n",
    "# *DONE* - remove timescaledb script\n",
    "# *DONE* - replace the unused notebook with the one from this demo\n",
    "# *DONE* - update dashboard yaml in the branch\n",
    "# *DONE* - add < now() to query (so we don't get ahead and can see how many records are needed for the threshold)\n",
    "# *DONE* - for each batch, run multiple models - one per univariate reading - and combine them into a single data frame and persist this.\n",
    "# *DONE* - profile timescaledb & grafana queries (add WHERE filter on time interval)\n",
    "\n",
    "# - fix permissions on create extension timescale_toolkit \n",
    "# *DONE* - fix permissions for service creation (postgresql-timescaledb)\n",
    "# *DONE* - try out some sort of multivariate-score averaging for an overall measurement (separate dashboard)\n",
    "# - add in an initial \"training\" window for setting the threshold (needed? would allow use of trained algos such as Prophet, and also for setting a threshold for SRs)\n",
    "# *DONE* - add lttb algorithm to reduce data points\n",
    "# - rename demo/branch to signal-processing\n",
    "\n",
    "# - add libraries to requirements at install/image?\n",
    "# - (low prio) add this script to a spark-streaming job (only when things are really finished?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fd08f7-9959-4d54-81e4-101c33f70f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
