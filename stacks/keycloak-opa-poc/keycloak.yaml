---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: keycloak
  labels:
    app: keycloak
spec:
  replicas: 1
  selector:
    matchLabels:
      app: keycloak
  template:
    metadata:
      labels:
        app: keycloak
    spec:
      containers:
        - name: keycloak
          image: quay.io/keycloak/keycloak:22.0.3
          # Keycloak is running in development mode: https://www.keycloak.org/server/configuration#_starting_keycloak
          # production mode disables HTTP and requires a TLS configuration, which is currently very difficult to configure
          # given that we're running on a NodePort
          args: ["start-dev"]
          env:
            - name: KEYCLOAK_ADMIN
              value: admin
            - name: KEYCLOAK_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: keycloak-admin-credentials
                  key: admin
          ports:
            - name: http
              containerPort: 8080
          readinessProbe:
            httpGet:
              path: /realms/master
              port: 8080
          volumeMounts:
            - name: data
              mountPath: /opt/keycloak/data/
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: keycloak-data
---
apiVersion: v1
kind: Service
metadata:
  name: keycloak
  labels:
    app: keycloak
spec:
# FIXME: We want a stable Keycloak address that does not change when Keycloak reboots.
# We could simply pick LoadBalancer here, but on-prem clusters often times don't support LBs,
# so the demo would not run on their environments. Additionally, LB addresses often take a while to allocate
# (order of minutes on GCP iirc). So there's no way for us to know whether there's no LB address because it's still
# in progress, or if there's no LB address because it's unsupported.
#
# We should at least make sure to reconcile the AuthClass once Keycloak restarts.
# We could achieve this by letting the keycloak itself propagate it's address instead of a separate Job.
  type: NodePort
  selector:
    app: keycloak
  ports:
    - name: http
      port: 8080
      targetPort: 8080
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: keycloak-data
spec:
  accessModes: [ReadWriteOnce]
  resources:
    requests:
      storage: 1Gi
---
apiVersion: v1
kind: Secret
metadata:
  name: keycloak-admin-credentials
stringData:
  admin: "{{ keycloakAdminPassword }}"
---
# This job creates a ConfigMap with connection info for Keycloak
apiVersion: batch/v1
kind: Job
metadata:
  name: propagate-keycloak-address
spec:
  template:
    spec:
      containers:
      - name: propagate-keycloak-address
        image: docker.stackable.tech/stackable/testing-tools:0.2.0-stackable0.0.0-dev # We need 0.0.0-dev, so we get kubectl
        command:
          - bash
          - -x
          - -euo
          - pipefail
          - -c
          - |
            echo "Determining Keycloak public reachable address"
            KEYCLOAK_ADDRESS=$(kubectl get svc keycloak -o json | jq -r --argfile endpoints <(kubectl get endpoints keycloak -o json) --argfile nodes <(kubectl get nodes -o json) '($nodes.items[] | select(.metadata.name == $endpoints.subsets[].addresses[].nodeName) | .status.addresses | map(select(.type == "ExternalIP" or .type == "InternalIP")) | min_by(.type) | .address | tostring) + ":" + (.spec.ports[] | select(.name == "http") | .nodePort | tostring)')
            echo "Found Keycloak running at $KEYCLOAK_ADDRESS"

            echo "Writing Keycloak address to ConfigMap keycloak"
            kubectl create configmap keycloak --from-literal="KEYCLOAK=$KEYCLOAK_ADDRESS" --from-literal="KEYCLOAK_DISCOVERY_URL=http://$KEYCLOAK_ADDRESS/realms/master/.well-known/openid-configuration" -o yaml --dry-run | kubectl apply -f -
      serviceAccountName: demo-serviceaccount
      restartPolicy: OnFailure
  backoffLimit: 20 # give some time for the Keycloak to be available
