stacks:
  monitoring:
    description: Stack containing Prometheus and Grafana
    stackableRelease: 23.4
    stackableOperators:
     - commons
    labels:
      - monitoring
      - prometheus
      - grafana
    manifests:
      - plainYaml: stacks/monitoring/grafana-dashboards.yaml
      - helmChart: stacks/_templates/prometheus.yaml
      - plainYaml: stacks/_templates/prometheus-service-monitor.yaml
    parameters:
      - name: grafanaAdminPassword
        description: Password of the Grafana admin user
        default: adminadmin
  logging:
    description: Stack containing OpenSearch, OpenSearch Dashboards (Kibana) and Vector aggregator
    stackableRelease: 23.4
    stackableOperators:
      - commons
      - secret
      - zookeeper # demo does install a zookeeper to produce logs
    labels:
      - logging
      - opensearch
      - opensearch-dashboards
      - vector
    manifests:
      - helmChart: stacks/_templates/opensearch.yaml
      - helmChart: stacks/_templates/opensearch-dashboards.yaml
      - helmChart: stacks/_templates/vector-aggregator.yaml
      - plainYaml: stacks/_templates/vector-aggregator-discovery.yaml
    parameters:
      - name: openSearchAdminPassword
        description: Password of the OpenSearch admin user
        default: adminadmin
      - name: openSearchDashboardPassword
        description: Password of OpenSearch Dashboard user
        default: kibanaserverkibanaserver
      - name: setSysctlMaxMapCount
        description: Wether an init-container should be used to increase 'sysctl -w vm.max_map_count'. This requires to spawn an init-container with runsAsUser 0 privileges, which some clusters prohibit. You can increase 'vm.max_map_count' on all of the kubernetes nodes manually and set this to 'false'.
        default: "true"
  airflow:
    description: Stack containing Airflow scheduling platform
    stackableRelease: 23.4
    stackableOperators:
      - commons
      - secret
      - airflow
      - spark-k8s # Some demo does schedule a Spark job
    labels:
      - airflow
    manifests:
      - helmChart: stacks/_templates/postgresql-airflow.yaml
      - helmChart: stacks/_templates/redis-airflow.yaml
      - plainYaml: stacks/airflow/airflow.yaml
    parameters:
      - name: airflowAdminPassword
        description: Password of the Airflow admin user
        default: adminadmin
      - name: airflowSecretKey
        description: Airflow's secret key used to generate e.g. user session tokens
        default: airflowSecretKey
  data-lakehouse-iceberg-trino-spark:
    description: Data lakehouse using Iceberg lakehouse on S3, Trino as query engine, Spark for streaming ingest and Superset for data visualization
    stackableRelease: 23.4
    stackableOperators:
      - commons
      - secret
      - hive
      - trino
      - opa
      - zookeeper
      - kafka
      - nifi
      - superset
      - spark-k8s
    labels:
      - iceberg
      - trino
      - spark
      - superset
      - kafka
      - nifi
      - minio
      - s3
    manifests:
      - helmChart: stacks/_templates/minio-distributed.yaml
      - helmChart: stacks/_templates/postgresql-hive.yaml
      - helmChart: stacks/_templates/postgresql-hive-iceberg.yaml
      - helmChart: stacks/_templates/postgresql-superset.yaml
      - plainYaml: stacks/data-lakehouse-iceberg-trino-spark/s3-connection.yaml
      - plainYaml: stacks/data-lakehouse-iceberg-trino-spark/hive-metastores.yaml
      - plainYaml: stacks/data-lakehouse-iceberg-trino-spark/trino.yaml
      - plainYaml: stacks/data-lakehouse-iceberg-trino-spark/zookeeper.yaml
      - plainYaml: stacks/data-lakehouse-iceberg-trino-spark/kafka.yaml
      - plainYaml: stacks/data-lakehouse-iceberg-trino-spark/nifi.yaml
      - plainYaml: stacks/nifi-kafka-druid-superset-s3/superset.yaml # Reuse
    parameters:
      - name: trinoAdminPassword
        description: Password of the Trino admin user
        default: trinoAdminPassword # adminadmin
      - name: supersetAdminPassword
        description: Password of the Superset admin user
        default: supersetAdminPassword # adminadmin
      - name: nifiAdminPassword
        description: Password of the MinIO admin user
        default: nifiAdminPassword # adminadmin
      - name: minioAdminPassword
        description: Password of the MinIO admin user
        default: minioAdminPassword # adminadmin
      - name: supersetSecretKey
        description: Superset's secret key used to generate e.g. user session tokens
        default: supersetSecretKey
  hdfs-hbase:
    description: HBase cluster using HDFS as underlying storage
    stackableRelease: 23.4
    stackableOperators:
      - commons
      - secret
      - zookeeper
      - hdfs
      - hbase
    labels:
      - hbase
      - hdfs
    manifests:
      - plainYaml: stacks/hdfs-hbase/zookeeper.yaml
      - plainYaml: stacks/hdfs-hbase/hdfs.yaml
      - plainYaml: stacks/hdfs-hbase/hbase.yaml
    parameters: []
  nifi-kafka-druid-superset-s3:
    description: Stack containing NiFi, Kafka, Druid, MinIO and Superset for data visualization
    stackableRelease: 23.4
    stackableOperators:
      - commons
      - secret
      - zookeeper
      - kafka
      - druid
      - superset
      - nifi
    labels:
      - nifi
      - kafka
      - druid
      - superset
      - minio
      - s3
    manifests:
      - helmChart: stacks/_templates/minio.yaml
      - helmChart: stacks/_templates/postgresql-druid.yaml
      - helmChart: stacks/_templates/postgresql-superset.yaml
      - plainYaml: stacks/nifi-kafka-druid-superset-s3/zookeeper.yaml
      - plainYaml: stacks/nifi-kafka-druid-superset-s3/kafka.yaml
      - plainYaml: stacks/nifi-kafka-druid-superset-s3/druid.yaml
      - plainYaml: stacks/nifi-kafka-druid-superset-s3/superset.yaml
      - plainYaml: stacks/nifi-kafka-druid-superset-s3/nifi.yaml
    parameters:
      - name: nifiAdminPassword
        description: Password of the NiFI admin user
        default: adminadmin
      - name: supersetAdminPassword
        description: Password of the Superset admin user
        default: adminadmin
      - name: minioAdminPassword
        description: Password of the MinIO admin user
        default: adminadmin
      - name: supersetSecretKey
        description: Superset's secret key used to generate e.g. user session tokens
        default: adminadmin
  spark-trino-superset-s3:
    description: Stack containing MinIO, Trino and Superset for data visualization
    stackableRelease: 23.4
    stackableOperators:
      - commons
      - secret
      - hive
      - trino
      - opa
      - superset
      - spark-k8s # Some demo does schedule a Spark job
    labels:
      - trino
      - superset
      - minio
      - s3
    manifests:
      - helmChart: stacks/_templates/minio.yaml
      - helmChart: stacks/_templates/postgresql-hive.yaml
      - helmChart: stacks/_templates/postgresql-hive-iceberg.yaml
      - helmChart: stacks/_templates/postgresql-superset.yaml
      - plainYaml: stacks/trino-superset-s3/s3-connection.yaml
      - plainYaml: stacks/spark-trino-superset-s3/hive-metastore.yaml
      - plainYaml: stacks/trino-superset-s3/trino.yaml
      - plainYaml: stacks/spark-trino-superset-s3/trino-prediction-catalog.yaml
      - plainYaml: stacks/trino-superset-s3/superset.yaml
    parameters:
      - name: trinoAdminPassword
        description: Password of the Trino admin user
        default: trinoAdminPassword # adminadmin
      - name: supersetAdminPassword
        description: Password of the Superset admin user
        default: supersetAdminPassword # adminadmin
      - name: minioAdminPassword
        description: Password of the MinIO admin user
        default: minioAdminPassword # adminadmin
      - name: supersetSecretKey
        description: Superset's secret key used to generate e.g. user session tokens
        default: supersetSecretKey
  trino-superset-s3:
    description: Stack containing MinIO, Trino and Superset for data visualization
    stackableRelease: 23.4
    stackableOperators:
      - commons
      - secret
      - hive
      - trino
      - opa
      - superset
    labels:
      - trino
      - superset
      - minio
      - s3
    manifests:
      - helmChart: stacks/_templates/minio.yaml
      - helmChart: stacks/_templates/postgresql-hive.yaml
      - helmChart: stacks/_templates/postgresql-superset.yaml
      - plainYaml: stacks/trino-superset-s3/s3-credentials.yaml
      - plainYaml: stacks/trino-superset-s3/hive-metastore.yaml
      - plainYaml: stacks/trino-superset-s3/trino.yaml
      - plainYaml: stacks/trino-superset-s3/superset.yaml
    parameters:
      - name: trinoAdminPassword
        description: Password of the Trino admin user
        default: adminadmin
      - name: supersetAdminPassword
        description: Password of the Superset admin user
        default: adminadmin
      - name: minioAdminPassword
        description: Password of the MinIO admin user
        default: adminadmin
      - name: supersetSecretKey
        description: Superset's secret key used to generate e.g. user session tokens
        default: supersetSecretKey
  trino-iceberg:
    description: Stack containing Trino using Apache Iceberg as a S3 data lakehouse
    stackableRelease: 23.4
    stackableOperators:
      - commons
      - secret
      - hive
      - trino
    labels:
      - trino
      - opa
      - iceberg
      - minio
      - s3
    manifests:
      - helmChart: stacks/_templates/minio-distributed-small.yaml
      - helmChart: stacks/_templates/postgresql-hive-iceberg.yaml
      - plainYaml: stacks/trino-iceberg/s3-connection.yaml
      - plainYaml: stacks/trino-iceberg/hive-metastores.yaml
      - plainYaml: stacks/trino-iceberg/trino.yaml
    parameters:
      - name: trinoAdminPassword
        description: Password of the Trino admin user
        default: adminadmin
      - name: minioAdminPassword
        description: Password of the MinIO admin user
        default: adminadmin
  jupyterhub-pyspark-hdfs:
    description: Jupyterhub with PySpark and HDFS integration
    stackableRelease: 23.4
    stackableOperators:
      - commons
      - secret
      - zookeeper
      - hdfs
      - spark-k8s
    labels:
      - jupyterhub
      - hdfs
      - pyspark
    manifests:
      - helmChart: stacks/_templates/jupyterhub.yaml
      - plainYaml: stacks/jupyterhub-pyspark-hdfs/zookeeper.yaml
      - plainYaml: stacks/jupyterhub-pyspark-hdfs/hdfs.yaml
      - plainYaml: stacks/jupyterhub-pyspark-hdfs/serviceaccount.yaml
      - plainYaml: stacks/jupyterhub-pyspark-hdfs/spark_driver_service.yaml
    parameters:
      - name: jupyterHubAdminPassword
        description: Password of the JupyterHub admin user
        default: adminadmin
  dual-hive-hdfs-s3:
    description: Dual stack Hive on HDFS and S3 for Hadoop/Hive to Trino migration
    stackableRelease: 23.4
    stackableOperators:
      - commons
      - secret
      - zookeeper
      - hdfs
      - hive
      - trino
      - opa
    labels:
      - trino
      - hive
      - hdfs
      - s3
    manifests:
      - helmChart: stacks/_templates/postgresql-hivehdfs.yaml
      - helmChart: stacks/_templates/postgresql-hives3.yaml
      - helmChart: stacks/_templates/minio.yaml
      - plainYaml: stacks/dual-hive-hdfs-s3/hdfs.yaml
      - plainYaml: stacks/dual-hive-hdfs-s3/hive.yaml
      - plainYaml: stacks/dual-hive-hdfs-s3/trino.yaml
    parameters: []
  tutorial-openldap:
    description: >-
      An OpenLDAP instance with two users (alice:alice, bob:bob) and TLS enabled.
      The bind user credentials are: ldapadmin:ldapadminpassword.
      No AuthenticationClass is configured, The AuthenticationClass is created manually in the tutorial.
      Use the 'openldap' Stack for an OpenLDAD with an AuthenticationClass already installed.
    stackableRelease: 23.4
    stackableOperators:
      - commons
      - secret
    labels:
      - authentication
      - ldap
    manifests:
      - plainYaml: stacks/authentication/openldap-tls.yaml
    # TODO: Parameterize
    parameters: []
  openldap:
    description: >-
      An OpenLDAP instance with two users (alice:alice, bob:bob) and TLS enabled.
      The bind user credentials are: ldapadmin:ldapadminpassword.
      The LDAP AuthenticationClass is called 'ldap' and the SecretClass for the bind credentials is called 'ldap-bind-credentials'.
      The stack already creates an appropriate Secret, so referring to the 'ldap' AuthenticationClass in your ProductCluster should be enough.
    stackableRelease: 23.4
    stackableOperators:
      - commons
      - secret
    labels:
      - authentication
      - ldap
    manifests:
      - plainYaml: stacks/authentication/openldap-tls.yaml
      - plainYaml: stacks/authentication/openldap-tls-authenticationclass.yaml
    # TODO: Parameterize
    parameters: []
